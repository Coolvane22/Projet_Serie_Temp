---
title: "Projet série temporelles"
author: "Beguec, Cavenne, Goutard & Thivend"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Importation des librairies
```{r}
lib <- c("tidyverse", "lubridate", "forecast", "plyr", "plotly")
sapply(lib, require, character = TRUE)
```

# Importation et traitements des données 
Source des données : https://www.insee.fr/fr/statistiques/series/102765746
Le jeu de données concerne les dépenses cumulées de l'Etat pour la période de janvier 2009 à janvier 2022.
```{r}
## Importation des donnees :
caracteristiques <- read_delim("data/caractéristiques.csv", delim =";")
v_mensuelles <- read_delim("data/valeurs_mensuelles.csv", delim =",")
head(caracteristiques)
head(v_mensuelles)

## On garde uniquement les colonnes utiles
vm_depenses <- v_mensuelles %>% 
  select("Libellé","Situation mensuelle du budget de l'État - Dépenses - Cumul depuis le début de l'année" )
colnames(vm_depenses) <- c("date", "depenses")

## On convertit la colonne date au format date
vm_depenses$date <- ym(vm_depenses$date)

## On convertit les valeurs des depenses cumulees en valeurs mensuelles non-cumulees
for (j in 1:13){
  for (i in 2:12){
     vm_depenses[i+((j-1)*12), 2] <- vm_depenses[i+((j-1)*12), 2] - sum(vm_depenses[(1+((j-1)*12)):((i-1)+ ((j-1)*12)), 2])
   }
}
```
Nous avons décidé d'utiliser les dépenses non-cumulées. Leur unité est exprimée en million d'euros.


# Etude du modèle global  

## Série brute  
```{r}
## Visualisation du  Month.plot 
ts = ts(vm_depenses$depenses, frequency=12)
forecast::ggmonthplot(ts)

## Visualisation de la série brute 
ts %>% 
  ggtsdisplay(
    plot.type = "scatter"
  )

## Visualisation du Lagplot 
forecast::gglagplot(ts, lags = 12, do.lines = FALSE)
```
*Interprétation du monthplot* : Le monthplot montre qu'il semble exister une saisonalité et une tendance. En effet, d'une année sur l'autre, les dépenses se suivent plus ou moins de cette façon :
- janvier février mai juin (voir décembre) : moyenne entre 30000 et 35000 millions d'euros
- mars août septembre novembre : moyenne entre 25000 et 28000 millions d'euros
- juillet octobre et avril beaucoup de dépenses (particulièrement bien au-dessus des autres mois pour avril)
On remarque globalement une tendance à la hausse au fil des années, sûrement lié à l'inflation ou à la crise économique.  

*Interprétation de l'ACF* : En regardant les auto-corrélations, on remarque des pics fortement positifs (et d'autres faiblement négatifs) ainsi qu'un schéma périodique de période 12.On remarque aussi un shéma périodique moins important de période 3 et 6.

*Interprétation du lagplot* : L'axe y montre les valeurs décalées de la série chronologique. Chaque graphique montre Yt tracé en fonction de Yt_k pour différentes valeurs de k. 
On voit que la relation est fortement positive au décalage 12, ce qui reflète la saisonnalité des données et nous rassure sur l'interprétation de l'ACF.   


### Tendance
```{r}
## degre 1
a = data.frame(t = 1:156, x = ts %>% diff(differences = 1), ordre = "k = 1")
mean(a$x) # 84.95513
## degre 2
b = data.frame(t = 1:155, x = ts %>% diff(differences = 2), ordre = "k = 2")
mean(b$x) # -174.1355
## degre 3
c = data.frame(t = 1:154, x = ts %>% diff(differences = 3), ordre = "k = 3")
mean(c$x) # -59.77273
## degre 4
d = data.frame(t = 1:153 , x = ts %>% diff(differences = 4), ordre = "k = 4")
mean(d$x) # -593.5948
df = bind_rows(a,b,c,d)

## Comparaison des differents degres
ggplot(data = df, aes(x = t, y = x, color = ordre)) +
  geom_line() +
  facet_wrap( ~ ordre)


## On enleve la tendance (Degre 1 donc differences=1) :
serie_wo_tendance <- diff(ts, differences=1)

```
Nous testons plusieurs degrés de l'opérateur différence afin de savoir si une tendance linéaire ou polynomiale modélise bien la tendance. 
Le degré 1 semble avoir bien supprimé la tendance : plus de croissance et la moyenne est du même ordre de grandeur que 0 (84.95513). 

### Saisonnalité
```{r}
## On teste differentes valeurs pour la periode de la saisonnalite. On teste avec 3, 6, 9 et 12
par(mfrow = c(2,2))
Acf(serie_wo_tendance %>% diff(lag = 3), main="Lag = 3")
Acf(serie_wo_tendance %>% diff(lag = 6), main="Lag = 6")
Acf(serie_wo_tendance %>% diff(lag = 9), main="Lag = 9")
Acf(serie_wo_tendance %>% diff(lag = 12), main="Lag = 12")

## On enleve la saisonnalite
serie_wo_tendance %>% 
  diff(lag=12) %>% 
  ggtsdisplay()

## Serie sans tendance ni saisonnalite
serie_wo_ts <- diff(serie_wo_tendance, lag=12)

```
La saisonnalité a été supprimé seulement pour l'opérateur de différence saisonnière de lag = 12 : on enlève donc les hypothèses de saisonnalité 3, 6 et 9.

### Estimation par MCO
```{r}
## Regression lineaire
t <- 1:length(ts)
x <- outer(t,1:6)*(pi/6)
df <- data.frame(ts, t, cos(x), sin(x[,-6]))
ts_lm <- lm(data = df, ts ~ .)

## Etude des residus
ggtsdisplay(ts_lm$residuals, plot.type = "scatter")
ggtsdisplay(ts_lm$residuals)
pacf(ts_lm$residuals)

## Test du bruit blanc
Box.test(ts_lm$residuals, lag=13, type="Ljung-Box")
# p-val < 0.05 donc pas de bruit blanc : il y a bien quelque chose a modeliser dans la partie non deterministe

## Test de stationnarite
urca::ur.kpss(ts_lm$residuals) # on accepte h0 : on est sur un processus stationnaire

```
Notre série n'étant pas un bruit blanc mais bien stationnaire, nous pouvous nous interésser à estimer notre composante aléatoire.
Nous regardons l'ACF et le PACF afin de déterminer quel processus approchera le mieux notre composante aléatoire :nous voyons que l'ACF s'annule à partir de l'ordre 13, et que le PACF s'annule à partir de l'ordre 15. 
Nous avons donc 3 processus possibles à tester : AR(15), MA(13) et la combinaison ARMA(15,13).


### AR
```{r}
ts_ar <- Arima(y = ts_lm$residuals, order = c(15,0,0)) #AR(15)

## Test de blancheur :
Box.test(ts_ar$resid, lag=13, type="Ljung-Box") # bruit blanc donc stationnarité
# Le choix de h doit être aussi grand que la stationnarité
```
*Test de blancheur* : On teste l'hypothèse nulle H0 : Tous les coefficients sont nuls, contre l'hypothèse H1 : Au moins un des coefficients est non-nul. On souhaite être sous H0 pour être en situation de bruit blanc. Le test de Ljung-Box donne une p-value = 0.9999. Cette p-value étant supérieure à 5%, on ne rejette pas H0, nous somme donc en situation de bruit blanc. 

### MA
```{r}
ts_ma <- Arima(y = ts_lm$residuals, order = c(0,0,13)) # MA(13)

## Test de blancheur :
Box.test(ts_ma$resid, lag=13, type="Ljung-Box") 
# On teste pour h plus grand que la saisonnalité :
```
P-value du test de blancheur supérieure à 5%, on est donc en présence d'un bruit blanc. 

### ARMA
```{r}
ts_arma <- Arima(y = ts_lm$residuals, order = c(15,0,13)) # ARMA(15, 13)

## Test de blancheur :
Box.test(ts_arma$resid, lag=13, type="Ljung-Box") 
```
La p-value du test de blancheur est égal à 1, on est donc en présence d'un bruit blanc.

### ARIMA
```{r}
auto.arima(ts_lm$residuals, trace=TRUE)

ts_arima <- Arima(y = ts_lm$residuals, order = c(2,1,4), method = "ML") 

## Test de blancheur :
Box.test(ts_arima$resid, lag=12, type="Ljung-Box") 
```
L'algorithme suggère les ordres suivants  p = 2, d = 1 et q = 4 : on retrouve donc l'opérateur différence d'ordre 1.

P-value du test de blancheur inférieure à 5% donc on rejette H0 : nous ne sommes pas en présence d'un bruit blanc. Ce qui est logique puisqu'un ARIMA avec ordre d > 0 n'est pas un processus stationnaire.


### COMPARAISONS DES MODELES
#### AIC
```{r}
ts_ar$aic
ts_ma$aic
ts_arma$aic
ts_arima$aic
```
Préférence pour l'AR(15).

#### BIC
```{r}
ts_ar$bic
ts_ma$bic
ts_arma$bic
ts_arima$bic
```
Préférence pour l'ARIMA.

#### AICC (AIC corrigé)
```{r}
ts_ar$aicc
ts_ma$aicc
ts_arma$aicc
ts_arima$aicc
```
Préférence pour l'AR(15).

Suite à ces comparaisons, on peut avoir une légère préférence pour l'AR(15).
On superpose notre modèle crée et nos données:
```{r}
dates <- time(ts)
p1 <- ggplot() +
  geom_line(aes(x = dates, y = ts,colour="depenses")) +
  geom_line(aes(x = dates, y = ts_lm$fitted+ts_ar$residuals,colour="modele"))+
  scale_color_manual(name = "series", values = c("depenses" = "darkblue", "modele" = "red"))
p1
```


## Etude du modele 2017 - 2022
On se concentre ici sur le quinquennat mai 2017 - janvier 2022.
```{r}
vm_depenses_2017_2022 <- vm_depenses %>% 
  filter(date > "2017-05-01" )

head(vm_depenses_2017_2022)
```

Visualisation des dépenses de mai 2017 à janvier 2022.
```{r}
vm_depenses_2017_2022 %>% 
  plot_ly(type = "scatter", mode = "lines") %>% 
  add_trace( x = ~date, y=~depenses) 
```
Avec la visualisation du graphique, on observe en général des pics de dépenses pour les mois d'avril et d'octobre. Nous supposons donc une saisonnalite de 6 mois. Au fil des années, on identifie clairement une tendance à la hausse. Cette augmentation des dépenses commencent en mars 2020. Ces dépenses s'expliquent par le début de la crise de la Covid-19, et continue donc jusqu'à la fin de notre jeu de données (décembre 2022).


On transforme les données en serie temporelles et on les visualise
```{r}
ts.depenses_2017_2022 = ts(vm_depenses_2017_2022$depenses, vm_depenses_2017_2022$date)

ts.depenses_2017_2022 %>% 
  ggtsdisplay(
    plot.type = "scatter"
  )
```
L'ACF nous montre les valeurs de la fonction d'auto-covariance, donc de la dépendance entre les observations à chaque décalage.
On identifie donc une valeur élevé pour 6 et 12. On est donc en présence d'une saisonnalité de 6 mois.


## Prévisions 

Nous ne disposons des données uniquement jusqu'à janvier 2022. Mais depuis la récupération de nos données, l'INSEE a publié les résultats pour le mois de février 2022 :
- janvier 2022 : 35 417
- février 2022 : 68 731 (valeurs cumulée pour janvier et février 2022)
--> Donc une prévision proche de 33 314 (68731 - 35417) serait satisfaisante.

```{r}
newt <- 1:(length(ts)+1)
newx <- outer(newt,1:6)*(pi/6)
newdf <- data.frame(ts=0,t=newt, cos(newx), sin(newx[,-6]))
newdf<-newdf[158,]
pred_lm = predict(ts_lm, newdata = newdf)

# Prédictions pour l'AR
pred_ar = predict(ts_ar)$pred
pred_ar = pred_ar+pred_lm
pred_ar

# Prédictions pour le MA
pred_ma = predict(ts_ma)$pred
pred_ma = pred_ma+pred_lm
pred_ma

# Prédictions pour l'ARMA
pred_arma = predict(ts_arma)$pred
pred_arma = pred_arma+pred_lm
pred_arma

# Prédictions pour l'ARIMA
pred_arima = predict(ts_arima)$pred
pred_arima = pred_arima+pred_lm
pred_arima
```
Les prévisions sont plutôt satisfaisantes. La prévision la plus proche de la réalité reste la prévision avec l'AR(15). Cela nous confirme donc notre théorie.